{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 參考資料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Python 使用 requests 模組產生 HTTP 請求，下載網頁資料教學](https://blog.gtwang.org/programming/python-requests-module-tutorial/)\n",
    "* [Python 使用 Beautiful Soup 抓取與解析網頁資料，開發網路爬蟲教學](https://blog.gtwang.org/programming/python-beautiful-soup-module-scrape-web-pages-tutorial/)\n",
    "* [正則表達式_regular expression](https://hackmd.io/@Hh_agMATRciWBNEnBwNQtQ/SJ4ubUh8I)\n",
    "* [tqdm_1](https://github.com/tqdm/tqdm)\n",
    "* [tqdm_2](https://tqdm.github.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos_dict = {}\n",
    "infos_dict['Location'] = []\n",
    "infos_dict['phone'] = []\n",
    "infos_dict['address'] = []\n",
    "infos_dict['ip'] = []\n",
    "infos_dict['webisite'] = []\n",
    "data_dict ={}\n",
    "data_dict['Location_URL'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Location\n",
    "pagenum=63\n",
    "pageurl = 'https://www.taiwan.net.tw/m1.aspx?sNo=0000064&page={}'\n",
    "for page in tqdm(range(pagenum)):\n",
    "    resp = requests.get(pageurl.format(page+1))\n",
    "    soup = BeautifulSoup(resp.text, 'lxml')\n",
    "    for tourist in soup.find_all(\"div\",{\"class\":\"card-title\"}) :\n",
    "        s1=tourist.text\n",
    "        infos_dict['Location'].append(s1)\n",
    "        print(s1)\n",
    "    for tourist_url in soup.find(\"ul\",{\"class\":\"grid card-list card-style-columns\"}).find_all(\"a\",{\"class\":\"card-link\"}) :\n",
    "        Url=\"https://www.taiwan.net.tw/\" + tourist_url.get('href')\n",
    "        data_dict['Location_URL'].append(Url)\n",
    "        print(Url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(infos_dict['Location']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_dict['Location_URL']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.DataFrame.from_dict(infos_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=['Oops!']\n",
    "infos_dict['phone'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(data_dict['Location_URL']))):\n",
    "    resp = requests.get(data_dict['Location_URL'][i])\n",
    "    soup = BeautifulSoup(resp.text, 'lxml')\n",
    "    phone=[tag.text for tag in soup.find(\"dl\",{\"class\":\"info-table\"}).find_all(\"a\",{\"class\":\"tel-link phone\"})]\n",
    "    if phone :\n",
    "        infos_dict['phone'].extend(phone)\n",
    "        print(i)\n",
    "    else:\n",
    "        print (\"empty\")\n",
    "        infos_dict['phone'].extend(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(infos_dict['phone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos_dict['phone']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos_dict['address'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_dict['Location_URL'])):\n",
    "    resp = requests.get(data_dict['Location_URL'][i])\n",
    "    soup = BeautifulSoup(resp.text, 'lxml')\n",
    "    address=[tag.text for tag in soup.find(\"dl\",{\"class\":\"info-table\"}).find_all(\"a\",{\"class\":\"tel-link address\"})]\n",
    "    if address :\n",
    "        infos_dict['address'].extend(address)\n",
    "        print(i)\n",
    "    else:\n",
    "        print (\"empty\")\n",
    "        infos_dict['address'].extend(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos_dict['address']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 經緯度(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos_dict['ip'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "for i in range(len(data_dict['Location_URL'])):\n",
    "    resp = requests.get(data_dict['Location_URL'][i])\n",
    "    soup = BeautifulSoup(resp.text, 'lxml')\n",
    "    #ip=[tag.text for tag in soup.find(\"dl\",{\"class\":\"info-table\"}).find_all(\"dd\",text=re.compile(\"12(0|1|2|3|4|5|6)+/\"))]\n",
    "\n",
    "    #if ip :\n",
    "    #    infos_dict['ip'].extend(ip)\n",
    "    #    print(i)\n",
    "    #else:\n",
    "    #    print (\"empty\")\n",
    "    #    infos_dict['ip'].extend(a)\n",
    "    ip=[tag.text for tag in soup.find(\"dl\",{\"class\":\"info-table\"}).find_all(\"dd\")]\n",
    "    ip_process =\"\".join(ip)\n",
    "    ip_final = re.findall(\"[0-9]+.[0-9]+/[0-9]+.[0-9]+\", ip_process)    \n",
    "    \n",
    "    if ip_final :\n",
    "        infos_dict['ip'].extend(ip_final)\n",
    "        print(i)\n",
    "    else:\n",
    "        print (\"empty\")\n",
    "        infos_dict['ip'].extend(a)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(infos_dict['ip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos_dict['ip']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# webisite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Python 使用 Beautiful Soup 抓取與解析網頁資料，開發網路爬蟲教學](https://blog.gtwang.org/programming/python-beautiful-soup-module-scrape-web-pages-tutorial/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos_dict['webisite'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_dict['Location_URL'])):\n",
    "    resp = requests.get(data_dict['Location_URL'][i])\n",
    "    soup = BeautifulSoup(resp.text, 'lxml')\n",
    "    webisite=[tag.get('href') for tag in soup.find(\"dl\",{\"class\":\"info-table\"}).find_all(\"a\",{\"class\":\"tel-link webside\"})]\n",
    "    if webisite :\n",
    "        infos_dict['webisite'].extend(webisite)\n",
    "        print(i)\n",
    "    else:\n",
    "        print (\"empty\")\n",
    "        infos_dict['webisite'].extend(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos_dict['webisite']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(infos_dict['webisite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.DataFrame.from_dict(infos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('crawling_ok_2020-05-03.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
